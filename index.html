<!DOCTYPE html>
<html lang="zh-CN">

<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <!-- 上述3个meta标签*必须*放在最前面，任何其他内容都*必须*跟随其后！ -->
  <title>何涛 | Tao He</title>
  <!-- 最新版本的 Bootstrap 核心 CSS 文件 -->
  <link rel="stylesheet" href="https://cdn.bootcss.com/bootstrap/3.3.7/css/bootstrap.min.css"
    integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">

  <!-- 可选的 Bootstrap 主题文件（一般不用引入） -->
  <link rel="stylesheet" href="https://cdn.bootcss.com/bootstrap/3.3.7/css/bootstrap-theme.min.css"
    integrity="sha384-rHyoN1iRsVXV4nD0JutlnGaslCJuC7uwjduW9SVrLvRYooPp2bWYgmgJQIXwl/Sp" crossorigin="anonymous">

  <!-- 最新的 Bootstrap 核心 JavaScript 文件 -->
  <script src="https://cdn.bootcss.com/bootstrap/3.3.7/js/bootstrap.min.js"
    integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous">
  </script>
  <!--[if lt IE 9]>
      <script src="https://cdn.bootcss.com/html5shiv/3.7.3/html5shiv.min.js"></script>
      <script src="https://cdn.bootcss.com/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->
  <style type="text/css">
    body,
    button,
    input,
    select,
    textarea,
    h1,
    h2,
    h3,
    h4,
    h5,
    h6 {
      font-family: Times New Roman, sans-serif, Microsoft YaHei;
    }

    address,
    p,
    .nav {
      font-size: 18px;
    }
  </style>
</head>

<body data-gr-c-s-loaded="true">
  <dvi class="container">
    <div>
      <div class="row">
        <div class="col-sm-3 col-sm-offset-1">
          <div class="row">
            <img src="hetao.jpg" class="img-responsive img-rounded right-block" width="40%" alt="Tao He" />
            <div class="caption ">
              <h3 class="text-left">何涛 助理研究员</h3>
              <address class="text-left">
                <strong>四川大学智能医学中心</strong><br>
                机器智能实验室<br>计算机学院，四川大学<br>
                610065, 成都，中国<br>
                地址：成都市一环路南一段24号<br>
                <a href="mailto:#">主邮箱：taohescu@gmail.com</a> <br>
                <a href="mailto:#">副邮箱：tao_he@scu.edu.cn</a>
              </address>
              <br>
              <h3 class="text-left">Tao He</h3>
              <address class="text-left">
                <strong>Intelligent Medical Center of Sichuan University</strong><br>
                Machine Intelligence Laboratory <br>
                College of Computer Science <br>
                Sichuan University,<br>
                Chengdu 610065, P. R. China<br>
                <a href="mailto:#">taohescu@gmail.com</a> or <br>
                <a href="mailto:#">tao_he@scu.edu.cn</a>
              </address>
              <br>
            </div>
          </div>
          <div class="row">

          </div>
        </div>
        <div class="col-sm-6">
          <div id="about" class="page-header">
            <h2>简介 | About</h2>
            <p class="lead">何涛于2017年在四川大学计算机科学与技术攻读博士学位，导师是
              <a href="http://www.machineilab.org/users/zhangyi/index.html">
                章毅教授，IEEE Fellow
              </a>。于
              <a href="http://www.machineilab.org/">
                四川大学机器智能实验室
              </a>，从事人工智能、医学图像、口腔智能医学等研究。2021年12月毕业，现就职于四川大学计算机学院，任助理研究员
            </p>
            <p class="lead">Tao He is a Ph.D. candidate in computer science and technology from Sichuan University,
              Chengdu, China, from 2017, surprivised by Prof.<a
                href="http://www.machineilab.org/users/zhangyi/index.html">
                Zhang Yi, IEEE Fellow</a>. Now, he is an research assistant in Sichuan University. 

              His research intrest includes Deep Learning, Medical Imaging, and Stomatology Intelligent Medical in <a
                href="http://www.machineilab.org/">Machine Intelligence Laboratory</a>.</p>
          </div>
          <div id="publication" class="page-header">
            <h2>Journal Publications</h2>
            <h3> 2021 </h3>
            <div>
              <ul>
                
                <li>
                  <p class="lead">
                    <strong>Tao He</strong>, Jie Yao, Weidong Tian, Zhang Yi, Wei Tang, Jixiang Guo. Cephalometric Landmark
                    Detection by Considering Translational Invariance in the TwoStage
                    Framework, Neurocomputing, 2021, 464: 1526.
                  </p>
                </li>

                <li>
                  <p class="lead">
                    Jie Yao, Wei Zeng, <strong>Tao He</strong>, Shanluo Zhou, Yi Zhang, Jixiang Guo, Wei Tang,
                    Automatic localization of cephalometric landmarks based on convolutional neural network,
                    American Journal of Orthodontics and Dentofacial Orthopedics,
                    2021,
                    https://doi.org/10.1016/j.ajodo.2021.09.012.
                  </p>
                </li>

              </ul>
            </div>
            <h3> 2020 </h3>
            <div>
              <ul>
                <li>
                  <p class="lead">
                    <strong>T. He</strong>, L. Zhang, J. Guo, Z. Yi, “Multi‐label classification by exploiting
                    data‐driven pair‐wise label dependence,” Int J Intell Syst. vol. 35, no. 9, pp. 1375–1396, 2020. [<a
                      href="https://onlinelibrary.wiley.com/doi/abs/10.1002/int.22257">pdf</a>]
                  </p>
                </li>
                <li>
                  <p class="lead">
                    <strong>T. He</strong>, H. Mao, and Z. Yi, “Subtraction gates: Another way to learn long-term
                    dependencies in recurrent neural networks,” IEEE Transactions on Neural Networks and Learning
                    Systems, 2020. [<a href="https://ieeexplore.ieee.org/abstract/document/9310703">pdf</a>]

                  </p>
                </li>
                <li>
                  <p class="lead">
                    <strong>T. He</strong>, J. Hu, Y. Song, J. Guo, and Z. Yi, “Multi-task learning for the
                    segmentation of organs at risk with label dependence,” Medical Image Anal., vol. 61,
                    p. 101666, 2020. [<a
                      href="https://www.sciencedirect.com/science/article/pii/S1361841520300323">pdf</a>] [<a
                      href="https://github.com/ithet1007/MTL-SegTHOR">code</a>]
                  </p>
                </li>
              </ul>
            </div>
            <h3> 2019 </h3>
            <div>
              <ul>
                <li>
                  <p class="lead"> <strong>T. He</strong>, J. Guo, J. Wang, X. Xu, and Z. Yi, “Multi-task learning
                    for the segmentation of thoracic organs at risk in ct images,” in Proceedings of the
                    Challenge on Segmentation of THoracic Organs at Risk in CT Images, 2019. [<a
                      href="http://ceur-ws.org/Vol-2349/SegTHOR2019_paper_2.pdf">pdf</a>]
                  </p>
                </li>
                <li>
                  <p class="lead"> <strong>T. He</strong>, J. Guo, N. Chen, X. Xu, Z. Wang, K. Fu, L. Liu, and Z.
                    Yi, “Medimlp: Using grad-cam to extract principal variables for lung cancer postoperative
                    complication prediction,” IEEE Journal of Biomedical and Health Informatics, vol. 24, no. 6, pp.
                    1762–1771, 2019. [<a href="https://ieeexplore.ieee.org/document/8883038">pdf</a>]
                  </p>
                </li>
              </ul>
            </div>
            <h3> 2016 </h3>
            <div>
              <ul>
                <li>
                  <p class="lead"> <strong>T. He</strong>, H. Mao, and Z. Yi, “Moving object recognition using
                    multi-view three-dimensional convolutional neural networks,” Neural Computing and
                    Applications, vol. 28, pp. 3827–3835, 2016. [<a
                      href="http://link.springer.com/article/10.1007%2Fs00521-016-2277-9" target="_blank">pdf</a>]
                </li>
                <li>
                  <p class="lead"> <strong>T. He</strong>, H. Mao, J. Guo, and Z. Yi, “Cell tracking using deep
                    neural networks with multi-task learning,” Image and Vision Computing, vol. 60, pp. 142–153,
                    2016. [<a href="http://www.sciencedirect.com/science/article/pii/S0262885616302001"
                      target="_blank">pdf</a>][<a
                      href="https://pan.baidu.com/s/102bZ8b0-h-MOHGTsi7MNQQ">dataset{pcloud:nlym}</a>][<a
                      href="https://github.com/ithet1007/Cell-Tracking">code</a>]
                </li>
                <li>
                  <p class="lead"> B. Wu, J. Jia, <strong>T. He</strong>, J. Du, X. Yi, and Y. Ning, “Inferring
                    users’ emotions for human-mobile voice dialogue applications,” in Proceedings of the
                    International Conference on Multimedia and Expo (ICME), 2016, pp. 1–6. [<a
                      href="https://ieeexplore.ieee.org/document/7552890">pdf</a>]
                </li>
                <li>
                  <p class="lead"> J. Jia, J. Huang, G. Shen, <strong>T. He</strong>, Z. Liu, H. B. Luan, and C.
                    Yan, “Learning to appreciate the aesthetic effects of clothing,” in Proceedings of the 30th
                    Conference on Artificial Intelligence (AAAI), 2016, pp. 1216–1222. [<a
                      href="http://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/viewPDFInterstitial/12056/11725"
                      target="_blank">pdf</a>]</p>
                </li>
              </ul>
            </div>

          </div>
          <div id="professional" class="page-header">
            <h2>Professional Activities</h2>
            <h3>Journal Reviewer</h3>
            <ul>
              <li>
                <p>IEEE Transactions on Cybernetics (TCYB)</p>
              </li>
            </ul>
            <h3>Student Member of IEEE and IEEE Computational Intelligence Society (CIS).</h3>
            <ul>
            </ul>
            <h3>May,2015--Oct,2015. I went to Tsinghua University as an academic visitor. I did some affective computing
              research at Human Computer Speech Interaction Research Group for about five monthes.</h3>
            <ul>
          </div>
        </div>
        <div class="col-sm-2">
        </div>
      </div>
    </div>
    </div>

    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
    <script src="https://cdn.bootcss.com/jquery/1.12.4/jquery.min.js"></script>
    <!-- Include all compiled plugins (below), or include individual files as needed -->
    <script src="js/bootstrap.min.js"></script>
</body>

</html>