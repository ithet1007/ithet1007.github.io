<!DOCTYPE html>
<html lang="zh-CN">

<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <!-- 上述3个meta标签*必须*放在最前面，任何其他内容都*必须*跟随其后！ -->
  <title>何涛 | Tao He</title>
  <!-- 最新版本的 Bootstrap 核心 CSS 文件 -->
  <link rel="stylesheet" href="https://cdn.bootcss.com/bootstrap/3.3.7/css/bootstrap.min.css"
    integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">

  <!-- 可选的 Bootstrap 主题文件（一般不用引入） -->
  <link rel="stylesheet" href="https://cdn.bootcss.com/bootstrap/3.3.7/css/bootstrap-theme.min.css"
    integrity="sha384-rHyoN1iRsVXV4nD0JutlnGaslCJuC7uwjduW9SVrLvRYooPp2bWYgmgJQIXwl/Sp" crossorigin="anonymous">

  <!-- 最新的 Bootstrap 核心 JavaScript 文件 -->
  <script src="https://cdn.bootcss.com/bootstrap/3.3.7/js/bootstrap.min.js"
    integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous">
  </script>
  <!--[if lt IE 9]>
      <script src="https://cdn.bootcss.com/html5shiv/3.7.3/html5shiv.min.js"></script>
      <script src="https://cdn.bootcss.com/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->
  <style type="text/css">
    body,
    button,
    input,
    select,
    textarea,
    h1,
    h2,
    h3,
    h4,
    h5,
    h6 {
      font-family: Times New Roman, sans-serif, Microsoft YaHei;
    }

    address,
    p,
    .nav {
      font-size: 18px;
    }
  </style>
</head>

<body data-gr-c-s-loaded="true">
  <dvi class="container">
    <div>
      <div class="row">
        <div class="col-sm-3 col-sm-offset-1">
          <div class="row">
            <img src="hetao.jpg" class="img-responsive img-rounded right-block" width="40%" alt="Tao He" />
            <div class="caption ">
              <h3 class="text-left">何涛 副研究员 硕士生导师</h3>
              <address class="text-left">
                <strong>四川大学智能医学中心</strong><br>
                机器智能实验室<br>计算机学院，四川大学<br>
                610065, 成都，中国<br>
                地址：成都市一环路南一段24号<br>
                <a href="mailto:#">主邮箱：tao_he@scu.edu.cn</a> <br>
                <a href="mailto:#">副邮箱：taohescu@gmail.com</a>
              </address>
              <br>
              <h3 class="text-left">Tao He</h3>
              <address class="text-left">
                Machine Intelligence Laboratory <br>
                College of Computer Science <br>
                Sichuan University,<br>
                Chengdu 610065, P. R. China<br>
                <a href="mailto:#">taohescu@gmail.com</a> or <br>
                <a href="mailto:#">tao_he@scu.edu.cn</a>
              </address>
              <br>
            </div>
          </div>
          <div class="row">

          </div>
        </div>
        <div class="col-sm-6">
          <div id="about" class="page-header">
            <h2>简介 | About</h2>
            <p class="lead">何涛于2021年在四川大学计算机学院获得博士学位，目前在
              <a href="http://www.machineilab.org/users/zhangyi/index.html">
              </a>
              <a href="https://scumed.machineilab.org/">
                四川大学智能医学中心
              </a>从事人工智能、医学图像等研究，主要在医学图像无监督学习，医学图像关键点检测等相关领域开展研究。现就职于四川大学计算机学院，任副研究员。目前累计发表学术论文12篇，其中以第一作者或通讯作者身份发表论文9篇。已获得国家自然科学基金青年项目1项，博士后面上基金项目1项，四川省博士后特别资助项目1项。同时担任多个领域top期刊审稿人。
            </p>
            <p class="lead">Tao He is an associate researcher in colledge of computer science from Sichuan University,
              Chengdu, China. 

              His research interest includes Deep Learning, Medical Imaging, and Intelligent Medical in <a
                href="http://www.machineilab.org/">Machine Intelligence Laboratory</a>. Recently, he focus on medical image segmentation, medical image landmark detection, and etc.
              </p>
          </div>
          <div id="publication" class="page-header">
            <h2>Journal Publications</h2>

            <h3> 2023 </h3>
            <div>
              <ul>
                
                <li>
                  <p class="lead">
                    <strong>T. He</strong>, J. Guo, W. Tang, W. Zeng, P. He, F. Zeng, and Z. Yi, “Cascade-refine model for cephalometric landmark detection in high-resolution orthodontic images,” .<i>Knowledge-Based Systems</i>, p. 110332, 2023, doi: 10.1016/j.knosys.2023.110332.
                  </p>
                </li>

              </ul>
            </div>

            <h3> 2022 </h3>
            <div>
              <ul>
                
                <li>
                  <p class="lead">
                    J. Yao, W. Zeng, <strong>T. He</strong>, S. Zhou, Y. Zhang, J. Guo, and W. Tang,
                    “Automatic localization of cephalometric landmarks based on convolutional
                    neural network,” <i>American Journal of Orthodontics and
                    Dentofacial Orthopedics</i>, vol. 161, no. 3, pp. e250–e259, 2022, doi:
                    10.1016/j.ajodo.2021.09.012.
                  </p>
                </li>

              </ul>
            </div>

            <h3> 2021 </h3>
            <div>
              <ul>
                
                <li>
                  <p class="lead">
                    <strong>T. He</strong>, J. Yao, W. Tian, Z. Yi, W. Tang, and J. Guo, “Cephalometric
                    landmark detection by considering translational invariance in the twostage
                    framework,” <i>Neurocomputing</i>, vol. 464, pp. 15–26, 2021, doi:
                    10.1016/j.neucom.2021.08.042.
                  </p>
                </li>


              </ul>
            </div>
            <h3> 2020 </h3>
            <div>
              <ul>
                <li>
                  <p class="lead">
                    <strong>T. He</strong>, L. Zhang, J. Guo, and Z. Yi, “Multilabel classification by
                    exploiting data-driven pair-wise label dependence,” <i>International Journal
                    of Intelligent Systems</i>, vol. 35, no. 9, pp. 1375–1396, 2020, doi:
                    10.1002/int.22257.
                  </p>
                </li>
                <li>
                  <p class="lead">
                    <strong>T. He</strong>, H. Mao, and Z. Yi, “Subtraction gates: Another way to learn
                      long-term dependencies in recurrent neural networks,” <i>IEEE Transactions
                      on Neural Networks and Learning Systems</i>, pp. 1–12, 2020,
                      doi:10.1109/TNNLS.2020.3043752.
                  </p>
                </li>
                <li>
                  <p class="lead">
                    <strong>T. He</strong>, J. Hu, Y. Song, J. Guo, and Z. Yi, “Multi-task learning for the
                    segmentation of organs at risk with label dependence,” <i>Medical Image
                    Analysis</i>, vol. 61, p. 101666, 2020, doi: 10.1016/j.media.2020.101666.
                  </p>
                </li>

                <li>
                  <p class="lead">
                    <strong>T. He</strong>, J. Guo, N. Chen, X. Xu, Z. Wang, K. Fu, L. Liu, and Z. Yi,
                    “Medimlp: Using grad-cam to extract crucial variables for lung cancer
                    postoperative complication prediction,” <i>IEEE Journal of Biomedical
                    and Health Informatics</i>, vol. 24, no. 6, pp. 1762–1771, 2020, doi:
                    10.1109/JBHI.2019.2949601.
                  </p>
                </li>

              </ul>
            </div>
            <h3> 2019 </h3>
            <div>
              <ul>
                <li>
                  <p class="lead"> 
                    <strong>T. He</strong>, J. Guo, J. Wang, X. Xu, and Z. Yi, “Multi-task learning for the
                    segmentation of thoracic organs at risk in ct images.” in <i>SegTHOR@
                    ISBI</i>, 2019, pp. 10–13.
                  </p>
                </li>

              </ul>
            </div>

            <h3> 2017 </h3>
            <div>
              <ul>
                <li>
                  <p class="lead"> 
                    <strong>T. He</strong>, H. Mao, and Z. Yi, “Moving object recognition using multiview
                    three-dimensional convolutional neural networks,” <i>Neural computing
                    and applications</i>, vol. 28, no. 12, pp. 3827–3835, 2017, doi:
                    10.1007/s00521-016-2277-9.
                  </p>
                </li>
                <li>
                  <p class="lead"> 
                    <strong>T. He</strong>, H. Mao, J. Guo, and Z. Yi, “Cell tracking using deep neural networks
                    with multi-task learning,” <i>Image and Vision Computing</i>, vol. 60,
                    pp. 142–153, 2017, doi: 10.1016/j.imavis.2016.11.010.
                  </p>
                </li>

              </ul>
            </div>


            <h3> 2016 </h3>
            <div>
              <ul>
                <li>
                  <p class="lead"> 
                    B. Wu, J. Jia, <strong>T. He</strong>, J. Du, X. Yi, and Y. Ning, “Inferring users’
                    emotions for human-mobile voice dialogue applications,” in 2016 IEEE
                  <i>International Conference on Multimedia and Expo (ICME)</i>, 2016, pp.
                    1–6, doi: 10.1109/ICME.2016.7552890.
                  </p>
                </li>
                <li>
                  <p class="lead"> 
                    J. Jia, J. Huang, G. Shen, <strong>T. He</strong>, Z. Liu, H. Luan, and C. Yan, “Learning
                    to appreciate the aesthetic effects of clothing,” in Proceedings of <i> the
                    AAAI Conference on Artificial Intelligence</i>, vol. 30, no. 1, 2016.
                  </p>
                </li>

              </ul>
            </div>
          </div>

          <div id="fundation" class="page-header">
            <h2>Fundations</h2>
            <h4>National Natural Science Foundation
              of China. [Grant 62206189]</h4>
            <h4>Special Fund for the
              Postdoctoral Research of Sichuan Province. [Grant TB2022033]</h4>
              <h4>Special Fund for the
                China Postdoctoral Science Foundation. [Grant come soon.]</h4>
          </div>

          <div id="Fundations" class="page-header">
            <h2>Professional Activities</h2>
            <h3>Journal Reviewer</h3>
            <ul>
              <li>
                <p>IEEE Transactions on Cybernetics (TCYB)</p>
                <p>IEEE Transactions on Neural Network and Learning Systems (TNN)</p>
                <p>IEEE Transactions on Medical Imaging (TMI)</p>
                <p>IEEE Transactions on Image Processing (TIP)</p>
                <p>Neurocomputing</p>
                <p>Applied Intelligence</p>
              </li>
            </ul>

            <h4>Member of IEEE and IEEE Computational Intelligence Society (CIS).</h4>
            <h4>Member of Sichuan Institute of Artificial Intelligence.</h4>
            <ul>
            </ul>
            <h4>May,2015--Oct,2015. I went to Tsinghua University as an academic visitor. I did some affective computing
              research at Human Computer Speech Interaction Research Group for about five monthes.</h4>
            <ul>
          </div>
        </div>
        <div class="col-sm-2">
        </div>
      </div>
    </div>
    </div>

    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
    <script src="https://cdn.bootcss.com/jquery/1.12.4/jquery.min.js"></script>
    <!-- Include all compiled plugins (below), or include individual files as needed -->
    <script src="js/bootstrap.min.js"></script>
</body>

</html>